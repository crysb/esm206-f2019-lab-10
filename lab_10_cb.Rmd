---
title: "Lab 10 - Final - Multiple Linear Regression"
author: "Crystal Bae"
date: "12/2/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Packages needed
library(tidyverse)
library(janitor)
library(corrplot)

library(beepr) # just for fun!
# if you have long-running code, you don't have to look at it (plays sound)
# beep(#) Choose a number between 1-12
# Number 8 is super mario!

library(praise) # just for fun too! 
# says nice things. Try it: Enter praise() in any code chunk or in the console

library(stargazer) # For nice regression tables! 
# Hlavac, Marek (2018). stargazer: Well-Formatted Regression and Summary Statistics Tables.
#  R package version 5.2.2. https://CRAN.R-project.org/package=stargazer 
library(sf)
library(gganimate)
library(transformr)
library(here)
library(av)
```

### Objectives

- Multiple linear regression
- Check assumptions w/ diagnostic plots
- Make predictions for MLR with new data
- Intro to maps / spatial analysis in R & gganimate

### Multiple Linear Regression

```{r}
homes <- read_csv("slo_homes.csv") %>% 
  janitor::clean_names() %>% 
  filter(city %in% c("San Luis Obispo", "Atascadero", "Arroyo Grande"))
```

Look at correlations between numeric variables (checking to see if we think collinearity might be a concern). Ignore price_per_sq_ft since it's a calculated metric.

```{r}
# Creates correlation matrix:
homes_cor <- cor(homes[2:6])
homes_cor
```

Make a correlogram (plot of correlations):

```{r}
corrplot(homes_cor)
beep(2)
```

Start with a complete model including all variables for now:

```{r}
# linear model with outcome as price (assumes no interaction)
home_lm <- lm(price ~ city + bedrooms + bathrooms + sq_ft + status, 
              data = homes) 
home_lm
```

Let's interpret the model results.

- Since Atascadero and SLO show up in the model, the reference level is Arroyo Grande.
- With all else held equal, we would expect a home in Atascadero to sell $167,396 dollars LESS than a home in Arroyo Grande, on average.
- With all else held equal, a house in SLO would sell for $31,018 MORE than a home in Arroyo Grande.
- This model also suggests that for each additional bedroom, on average home price decreases by $161,645 for each additional bedroom. This is non-sensical, so think about collinearity! Might be explaining the same thing (home price) with highly-correlated variables. It's also treating the categorical variable of bedrooms as a continuous variable.

(Tip: A good guideline is at least 20 samples on each variable level you include in the regression.)

```{r}
home_lm2 <- lm(price ~ city + sq_ft + status, 
               data = homes)
home_lm2
```

On average, home price increases by $325 for every 1 sq ft increase in home size. (This is still pretty pricey, but makes sense for the central coast.)

AIC values:
This tells you about the balance between model fit and model complexity. Better model fit indicated by lower AIC value.

```{r}
AIC(home_lm) # values not meaningful on their own, but useful in comparison...
AIC(home_lm2)

# Be careful: AIC is not useful on its own! Consider your conceptual evidence from your interpretation of the data.
```

Let's check out the adjusted R-squared value to see model fit.

```{r}
summary(home_lm) # don't throw out coefficients based on significance alone!
summary(home_lm2) # simpler model, with coefficients that make sense, but slightly smaller adjusted R-squared
```

Let's ask `stargazer` package to create the summary regression table for us! Such a nightmare by hand.

```{r, results = 'asis'}
# results 'asis' because stargazer outputs to HTML already

stargazer(home_lm, home_lm2, type = "html")
# can also open this HTML table in Word to customize it, but can also customize thru stargazer directly (might be a pain)
```

Now let's check out diagnostic plots to see if our assumptions (normality of residuals and homoscedasticity) are satisfied or if we're really concerned:

- Linearly related variables
- Residuals normally distributed
- Variances constant
- Residuals iid (independent, uncorrelated)

```{r}
plot(home_lm2)
```

Make some home price predictions with new data. We're going to use that simplified model (home_lm2).

- First, create new data that contains city, sq_ft, status
- Give that new data to home_lm2 to make new predictions
- Plot it

```{r}
new_df <- data.frame(city = rep(c("San Luis Obispo", "Arroyo Grande", "Atascadero"), each = 10),
                     sq_ft = rep(seq(0, 5000, length = 10)),
                     status = "Regular")
```

Use `predict` function to make new predictions using home_lm2:

```{r}
predict_df <- predict(home_lm2, newdata = new_df)
```

# Bind that together with the new_df:

```{r}
full_df <- data.frame(new_df, predict_df)
```

Make a graph with the actual data, and what our model actually predicts:

```{r}
# if pulling from two sources, start with empty ggplot() call and add the data
ggplot() +
  geom_point(data = homes,
             aes(x = sq_ft, 
                 y = price, 
                 color = city, 
                 pch = city)) +
  geom_line(data = full_df,
            aes(x = sq_ft,
                y = predict_df,
                color = city)) +
  theme_light()

ggplot(data = homes, aes(x = sq_ft, y = price)) +
  geom_point() +
  geom_smooth(method = lm) +
  facet_wrap(~city)
```

### Intro to the `sf` package

`sf` = simple features

Has sticky geometry! Maintains the spatial information in the dataframe. This means we can just work with attributes like a normal data frame for wrangling, viz, etc.

Get the California dams data:

```{r}
dams <-  read_csv("ca_dams.csv") %>% 
  clean_names() %>% 
  drop_na(latitude) %>% # does complete row deletion for whatever variable you indicate with an 'na'
  drop_na(longitude) %>% 
  drop_na(year_completed)
```

Convert lat/long numbers to simple features data (sf)

```{r}
dams_sf <- st_as_sf(dams, coords = c("longitude", "latitude")) # indicate where your long/lat values are
st_crs(dams_sf) <- 4326 # set coordinate reference system

plot(dams_sf) # basic plot works OK for initial review
```

Now let's read in the shapefile data for the state of CA (outer boundary TIGER shapefile data).

```{r}
ca_border <- read_sf(here::here("ca_state_border"), layer = "CA_State_TIGER2016")
plot(ca_border) # if you look at the table for ca_border, it holds the entire geometry of the polygon in 'geometry'
```

Now, plot dams in California over the CA outline, in `ggplot`:

```{r}
ggplot() +
  geom_sf(data = ca_border, fill = "slate grey") +
  geom_sf(data = dams_sf,
          aes(size = dam_height),
          alpha = 0.5,
          color = "dark red",
          show.legend = FALSE)
```

Let's make an animated plot:

```{r}
ggplot() +
  geom_sf(data = ca_border) +
  geom_sf(data = dams_sf, size = 1, color = "gray50") +
  theme_void() +
  labs(title = "Year: {round(frame_time, 0)}") +
  transition_time(year_completed) + # animation time; give it the variable that contains that info
  shadow_mark(alpha = 1) # by default shows up & disappears, this makes sure they stay

beep(12)
```

